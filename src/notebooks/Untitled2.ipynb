{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random, Statistics, StatsBase\n",
    "using Lux, Optimisers, Zygote\n",
    "using MLDatasets, MLUtils, OneHotArrays\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = Random.default_rng()\n",
    "Random.seed!(rng, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 48\n",
    "\n",
    "x_train, y_train = MNIST(split=:train)[:]\n",
    "x_test, y_test = MNIST(split=:test)[:]\n",
    "\n",
    "x_train = reshape(x_train, size(x_train, 1), size(x_train, 2), 1, size(x_train, 3))\n",
    "y_train = onehotbatch(y_train, 0:9)\n",
    "(x_train, y_train), (x_val, y_val) = splitobs((x_train, y_train), at=0.9, shuffle=true)\n",
    "x_test = reshape(x_test, size(x_test, 1), size(x_test, 2), 1, size(x_test, 3))\n",
    "y_test = onehotbatch(y_test, 0:9)\n",
    "\n",
    "load_train = DataLoader((x_train, y_train); batchsize=batchsize, shuffle=true, partial=false)\n",
    "load_val = DataLoader((x_val, y_val); batchsize=batchsize, shuffle=false, partial=false)\n",
    "load_test = DataLoader((x_test, y_test); batchsize=batchsize, shuffle=false, partial=false)\n",
    "load_martingale = DataLoader((x_train, y_train); batchsize=1, shuffle=true, partial=false)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Conv((5, 5), 1 => 6, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    Conv((5, 5), 6 => 16, relu),\n",
    "    MaxPool((2, 2)),\n",
    "    FlattenLayer(3),\n",
    "    Chain(Dense(256 => 128, relu), Dense(128 => 84, relu), Dense(84 => 10)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, states = Lux.setup(rng, model)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "const lossfn = CrossEntropyLoss(; logits=Val(true))\n",
    "\n",
    "function loss(model, params, states, x, y)\n",
    "    yhat, new_states = model(x, params, states)\n",
    "    ls = mean(lossfn(yhat, y))\n",
    "    return ls, new_states\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validation(model, params, states, loader)\n",
    "    accs = Float64[]\n",
    "    for (x, y) in loader\n",
    "        yhat, _ = model(x, params, states)\n",
    "        push!(accs, mean(lossfn(yhat, y)))\n",
    "    end\n",
    "    \n",
    "    return mean(accs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function accuracy(model, params, states, loader)\n",
    "    accs = Float64[]\n",
    "    for (x, y) in loader\n",
    "        yhat, _ = model(x, params, states)\n",
    "        preds = onecold(yhat, 0:9)\n",
    "        labels = onecold(y, 0:9)\n",
    "        push!(accs, mean(preds .== labels))\n",
    "    end\n",
    "    \n",
    "    return mean(accs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimisers.Adam(1e-4 * batchsize)\n",
    "opt_state = Optimisers.setup(opt, params)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train!(model, params, states, opt_state, load_train, epochs)\n",
    "    time_start = time()\n",
    "    loss_val_0 = Inf\n",
    "    patience = 3\n",
    "    patience_ctr = 0\n",
    "    epoch_0 = 1\n",
    "    params_0, states_0, opt_state_0 = deepcopy((params, states, opt_state))\n",
    "    losses_train = Float64[]\n",
    "    losses_val = Float64[]\n",
    "    accs_test = Float64[]\n",
    "    \n",
    "    for epoch in 1:epochs\n",
    "        time_0 = time()\n",
    "        loss_train = 0.0\n",
    "        for (xb, yb) in load_train\n",
    "            # DataLoader implements its own iterator, thus this is reshuffled every epoch\n",
    "            (ls, new_states), back = Zygote.pullback(params -> loss(model, params, states, xb, yb), params)\n",
    "            states = new_states\n",
    "\n",
    "            grads = back((1f0, nothing))[1]\n",
    "            opt_state, params = Optimisers.update(opt_state, params, grads)\n",
    "            loss_train += ls\n",
    "        end\n",
    "        time_train = time() - time_0\n",
    "        loss_train = loss_train / length(load_train)\n",
    "        loss_val = validation(model, params, states, load_val)\n",
    "        time_val = time() - time_0 - time_train\n",
    "        acc_test = accuracy(model, params, states, load_test)\n",
    "        time_test = time() - time_0 - time_train - time_val\n",
    "        \n",
    "        println(\"Epoch $(epoch)\" * \n",
    "            \"\\n\\tloss_train = $(loss_train)\" * \"\\ttime_train = $(round(time_train, digits=4)) s\" * \n",
    "            \"\\n\\tloss_val   = $(loss_val)  \" * \"\\ttime_val   = $(round(time_val, digits=4)) s\" * \n",
    "            \"\\n\\tacc_test   = $(acc_test)  \" * \"\\ttime_test  = $(round(time_test, digits=4)) s\"\n",
    "        )\n",
    "        push!(losses_train, loss_train)\n",
    "        push!(losses_val, loss_val)\n",
    "        push!(accs_test, acc_test)\n",
    "\n",
    "        if loss_val < loss_val_0\n",
    "            loss_val_0 = loss_val\n",
    "            params_0, states_0, opt_state_0 = deepcopy((params, states, opt_state))\n",
    "            patience_ctr = 0\n",
    "            epoch_0 = epoch\n",
    "        else\n",
    "            patience_ctr += 1\n",
    "        end\n",
    "\n",
    "        if patience_ctr >= patience\n",
    "            println(\"Early stopping!\")\n",
    "            params, states, opt_state = params_0, states_0, opt_state_0\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    time_total = round(time() - time_start, digits=4)\n",
    "    println(\"Best epoch: $(epoch_0)\")\n",
    "    println(\"Total time: $(time_total) s\")\n",
    "    return params, states, opt_state, epoch_0, (losses_train, losses_val, accs_test)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 50_000\n",
    "epochs = nsteps ÷ batchsize\n",
    "println(\"nsteps = $(nsteps),\" * \"\\tbatchsize = $(batchsize),\" * \"\\tepochs = $(epochs)\")\n",
    "params, states, opt_state, epoch, losses = train!(model, params, states, opt_state, load_train, epochs)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = accuracy(model, params, states, load_test)\n",
    "println(\"Final test accuracy = $(acc_test)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = palette(:default)[1:10]\n",
    "plt = plot(size=(1000,500), layout=(1,2), margin=5Plots.mm)\n",
    "plot!(losses[1], subplot=1, label=\"training loss\", color=colors[1])\n",
    "plot!(losses[2], subplot=1, label=\"validation loss\", color=colors[2])\n",
    "vline!([epoch], subplot=1, label=\"early stopping\", color=colors[2], linestyle=:dash)\n",
    "plot!(losses[3], subplot=2, label=\"test accuracy\", color=colors[3])\n",
    "hline!([acc_test], subplot=2, label=\"early stopping\", color=colors[3], linestyle=:dash)\n",
    "title!(\"Loss during training\", subplot=1)\n",
    "title!(\"Final accuracy\", subplot=2)\n",
    "xlabel!(\"epochs\", subplot=1)\n",
    "xlabel!(\"epochs\", subplot=2)\n",
    "ylabel!(\"loss\", subplot=1)\n",
    "ylabel!(\"accuracy\", subplot=2)\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "function martingale_bootstrap!(model, params, states, load_martingale, niter)\n",
    "    iter = 1\n",
    "    for (xb, yb) in load_martingale\n",
    "        # DataLoader implements its own iterator, thus this is reshuffled every epoch\n",
    "        (ls, new_states), back = Zygote.pullback(params -> loss(model, params, states, xb, yb), params)\n",
    "        states = new_states\n",
    "\n",
    "        grads = back((1f0, nothing))[1]\n",
    "        ϵ = 1.0 / (100.0+iter)\n",
    "        params = Lux.fmap(params, grads) do ps, gs\n",
    "            ps .+ ϵ .* gs\n",
    "        end\n",
    "        # params = Lux.fmap((ps, gs) -> ps .+ ϵ .* gs, (params, grads))\n",
    "            # randn(rng, eltype(ps), size(ps))\n",
    "        \n",
    "        if iter < niter\n",
    "            iter += 1\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "function martingale_posterior!(model, params, states, load_martingale, niter)\n",
    "    iter = 1\n",
    "    for (xb, yb) in load_martingale\n",
    "        # DataLoader implements its own iterator, thus this is reshuffled every epoch\n",
    "        yhat, _ = model(xb, params, states)\n",
    "        probs = softmax(yhat; dims=1)\n",
    "        preds = sample(0:9, Weights(probs[:,1]))\n",
    "        yb = onehotbatch(preds, 0:9)\n",
    "        \n",
    "        (ls, new_states), back = Zygote.pullback(params -> loss(model, params, states, xb, yb), params)\n",
    "        states = new_states\n",
    "\n",
    "        grads = back((1f0, nothing))[1]\n",
    "        ϵ = 1.0 / (100.0+iter)\n",
    "        params = Lux.fmap(params, grads) do ps, gs\n",
    "            ps .+ ϵ .* gs\n",
    "        end\n",
    "        # params = Lux.fmap((ps, gs) -> ps .+ ϵ .* gs, (params, grads))\n",
    "            # randn(rng, eltype(ps), size(ps))\n",
    "        \n",
    "        if iter < niter\n",
    "            iter += 1\n",
    "        else\n",
    "            break\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return params\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_1 = martingale_bootstrap!(model, params, states, load_martingale, 200)\n",
    "params_2 = martingale_posterior!(model, params, states, load_martingale, 200)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = accuracy(model, params, states, load_test)\n",
    "acc_test_1 = accuracy(model, params_1, states, load_test)\n",
    "acc_test_2 = accuracy(model, params_2, states, load_test)\n",
    "println(\"Accuracy:\" * \n",
    "    \"\\n\\tinit = $(acc_test)\" * \n",
    "    \"\\n\\tboot = $(acc_test_1)\" * \n",
    "    \"\\n\\tpost = $(acc_test_2)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLAS.get_num_threads()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
